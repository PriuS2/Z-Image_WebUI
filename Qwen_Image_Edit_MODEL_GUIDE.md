# ovedrive/Qwen-Image-Edit-2511-4bit ëª¨ë¸ ì‚¬ìš© ê°€ì´ë“œ

[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-ovedrive%2FQwen--Image--Edit--2511--4bit-blue)](https://huggingface.co/ovedrive/Qwen-Image-Edit-2511-4bit)

> **ovedrive/Qwen-Image-Edit-2511-4bit**ëŠ” Qwen-Image-Edit-2511ì˜ **NF4 ì–‘ìí™” ë²„ì „**ìœ¼ë¡œ, ì›ë³¸ ëª¨ë¸ ëŒ€ë¹„ ì ˆë°˜ ì´í•˜ì˜ VRAMìœ¼ë¡œ ì´ë¯¸ì§€ í¸ì§‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

> ğŸ“Œ ì´ ë¬¸ì„œëŠ” **Windows í™˜ê²½**ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ì´ í”„ë¡œì íŠ¸ì—ì„œì˜ ì‚¬ìš©ë²•ì„ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

- [ëª¨ë¸ ê°œìš”](#ëª¨ë¸-ê°œìš”)
- [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
- [ëª¨ë¸ ë‹¤ìš´ë¡œë“œ](#ëª¨ë¸-ë‹¤ìš´ë¡œë“œ)
- [ëª¨ë¸ ë¡œë“œ](#ëª¨ë¸-ë¡œë“œ)
- [ëª¨ë¸ ì–¸ë¡œë“œ](#ëª¨ë¸-ì–¸ë¡œë“œ)
- [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
- [ìµœì í™” ë°©ë²•](#ìµœì í™”-ë°©ë²•)
- [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## ëª¨ë¸ ê°œìš”

### ê¸°ë³¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ëª¨ë¸ ID** | `ovedrive/Qwen-Image-Edit-2511-4bit` |
| **ì›ë³¸ ëª¨ë¸** | `Qwen/Qwen-Image-Edit-2511` |
| **ì–‘ìí™” ë°©ì‹** | NF4 (4-bit Normal Float) |
| **íŒŒì´í”„ë¼ì¸** | `QwenImageEditPlusPipeline` |
| **ê¶Œì¥ dtype** | `bfloat16` |

### ì™œ 4bit ì–‘ìí™” ëª¨ë¸ì¸ê°€?

| ë¹„êµ í•­ëª© | ì›ë³¸ (Qwen-Image-Edit-2511) | 4bit (ovedrive) |
|-----------|----------------------------|-----------------|
| ëª¨ë¸ í¬ê¸° | ~40GB | ~8.5GB |
| VRAM ìš”êµ¬ëŸ‰ | 24GB+ | 16GB (CPU Offload ì‹œ) |
| VRAM ìš”êµ¬ëŸ‰ (Full GPU) | 24GB+ | ~20GB |
| í’ˆì§ˆ | ê¸°ì¤€ | ê±°ì˜ ë™ì¼ (ë¯¸ì„¸í•œ ì°¨ì´) |
| ì¶”ë¡  ì†ë„ | ê¸°ì¤€ | ì•½ê°„ ë¹ ë¦„ |
| Windows í˜¸í™˜ì„± | bitsandbytes ë¬¸ì œ ê°€ëŠ¥ | âœ… ë¬¸ì œ ì—†ìŒ |

### ì£¼ìš” ì¥ì 

- âœ… **ë‚®ì€ VRAM ì‚¬ìš©ëŸ‰**: 16GB GPUì—ì„œë„ ì‹¤í–‰ ê°€ëŠ¥
- âœ… **Windows í˜¸í™˜ì„±**: bitsandbytes ì„¤ì • ë¶ˆí•„ìš” (ì´ë¯¸ ì–‘ìí™”ë¨)
- âœ… **diffusers í˜¸í™˜**: í‘œì¤€ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë°”ë¡œ ì‚¬ìš©
- âœ… **ë¹ ë¥¸ ë¡œë”©**: ë” ì‘ì€ ëª¨ë¸ í¬ê¸°ë¡œ ë¹ ë¥¸ ë¡œë“œ
- âœ… **10 ìŠ¤í…ì—ì„œë„ ì‘ë™**: ë‚®ì€ ì¶”ë¡  ìŠ¤í…ì—ì„œë„ í’ˆì§ˆ ìœ ì§€

---

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘

| êµ¬ì„± ìš”ì†Œ | ìµœì†Œ ì‚¬ì–‘ | ê¶Œì¥ ì‚¬ì–‘ |
|-----------|-----------|-----------|
| **GPU** | NVIDIA RTX 3060 (12GB) | NVIDIA RTX 3090/4070+ |
| **VRAM** | 12GB (CPU Offload í•„ìˆ˜) | 16GB+ |
| **RAM** | 24GB | 32GB+ |
| **ì €ì¥ ê³µê°„** | 15GB (ëª¨ë¸) | 25GB+ (ìºì‹œ í¬í•¨) |
| **Python** | 3.10+ | 3.11+ |
| **CUDA** | 11.8+ | 12.1+ |

### VRAMë³„ ê¶Œì¥ ì„¤ì •

| GPU VRAM | ê¶Œì¥ ì„¤ì • | ì„¤ëª… |
|----------|-----------|------|
| **24GB+** | `pipeline.to("cuda")` | ì „ì²´ GPU ë¡œë“œ, ìµœê³  ì†ë„ |
| **16-24GB** | `enable_model_cpu_offload()` | CPU ì˜¤í”„ë¡œë”©, ë¹ ë¥¸ ì†ë„ |
| **12-16GB** | CPU Offload + Attention Slicing | ë©”ëª¨ë¦¬ ì ˆì•½, ì¤‘ê°„ ì†ë„ |

---

## ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

### ë°©ë²• 1: APIë¥¼ í†µí•œ ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)

ì´ í”„ë¡œì íŠ¸ì˜ ë°±ì—”ë“œ ì„œë²„ë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### REST API ì‚¬ìš©

```bash
# ë‹¤ìš´ë¡œë“œ ì‹œì‘
curl -X POST "http://localhost:8000/api/model/download" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "ovedrive/Qwen-Image-Edit-2511-4bit",
    "force_download": false
  }'
```

```bash
# ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸
curl "http://localhost:8000/api/model/download/status" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

#### ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "success": true,
  "message": "Download status: downloading",
  "data": {
    "status": "downloading",
    "model_name": "ovedrive/Qwen-Image-Edit-2511-4bit",
    "progress_percent": 45.5,
    "downloaded_size_mb": 3890.5,
    "total_size_mb": 8550.0,
    "current_file": "model-00003-of-00005.safetensors",
    "files_completed": 2,
    "files_total": 5,
    "error_message": null
  }
}
```

#### Python í´ë¼ì´ì–¸íŠ¸ ì˜ˆì‹œ

```python
import requests
import time

API_URL = "http://localhost:8000"
API_KEY = "qwen-image-edit-default-key"
headers = {"X-API-Key": API_KEY}

# ë‹¤ìš´ë¡œë“œ ì‹œì‘
response = requests.post(
    f"{API_URL}/api/model/download",
    headers=headers,
    json={"model_name": "ovedrive/Qwen-Image-Edit-2511-4bit"}
)
print(response.json())

# ì§„í–‰ ìƒí™© í™•ì¸
while True:
    response = requests.get(f"{API_URL}/api/model/download/status", headers=headers)
    data = response.json()["data"]
    
    print(f"ğŸ“¥ ì§„í–‰ë¥ : {data['progress_percent']:.1f}%")
    
    if data["status"] == "completed":
        print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        break
    elif data["status"] == "failed":
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {data['error_message']}")
        break
    
    time.sleep(2)
```

### ë°©ë²• 2: Hugging Face CLI ë‹¤ìš´ë¡œë“œ

```powershell
# huggingface-cli ì„¤ì¹˜
pip install huggingface_hub

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
huggingface-cli download ovedrive/Qwen-Image-Edit-2511-4bit
```

### ë°©ë²• 3: Python ì§ì ‘ ë‹¤ìš´ë¡œë“œ

```python
from huggingface_hub import snapshot_download

# ëª¨ë¸ ì „ì²´ ë‹¤ìš´ë¡œë“œ
cache_dir = snapshot_download(
    repo_id="ovedrive/Qwen-Image-Edit-2511-4bit",
    resume_download=True  # ì¤‘ë‹¨ ì‹œ ì¬ê°œ ê°€ëŠ¥
)

print(f"âœ… ëª¨ë¸ ìºì‹œ ìœ„ì¹˜: {cache_dir}")
```

### ë‹¤ìš´ë¡œë“œ ì·¨ì†Œ

```bash
curl -X POST "http://localhost:8000/api/model/download/cancel" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

### ë‹¤ìš´ë¡œë“œ ì—¬ë¶€ í™•ì¸

```bash
# íŠ¹ì • ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
curl "http://localhost:8000/api/model/download/check/ovedrive%2FQwen-Image-Edit-2511-4bit" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

```json
{
  "success": true,
  "model_name": "ovedrive/Qwen-Image-Edit-2511-4bit",
  "is_downloaded": true
}
```

---

## ëª¨ë¸ ë¡œë“œ

### ë°©ë²• 1: APIë¥¼ í†µí•œ ë¡œë“œ (ê¶Œì¥)

#### ê¸°ë³¸ ë¡œë“œ (ì €ì¥ëœ ì„¤ì • ì‚¬ìš©)

```bash
curl -X POST "http://localhost:8000/api/model/load" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

#### ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ë¡œë“œ

```bash
curl -X POST "http://localhost:8000/api/model/load" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "ovedrive/Qwen-Image-Edit-2511-4bit",
    "optimization": {
      "enable_model_cpu_offload": true,
      "enable_attention_slicing": true,
      "enable_vae_slicing": true,
      "enable_vae_tiling": false,
      "enable_xformers": false
    },
    "force_reload": false
  }'
```

#### ë¡œë“œ ì˜µì…˜ ì„¤ëª…

| ì˜µì…˜ | íƒ€ì… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|------|--------|------|
| `model_name` | string | ì„¤ì • ê°’ | ë¡œë“œí•  ëª¨ë¸ ID |
| `optimization` | object | ì„¤ì • ê°’ | ìµœì í™” ì˜µì…˜ |
| `force_reload` | boolean | `false` | ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆì–´ë„ ì¬ë¡œë“œ |

#### ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "success": true,
  "message": "Model loaded successfully",
  "data": {
    "is_loaded": true,
    "model_name": "ovedrive/Qwen-Image-Edit-2511-4bit",
    "device": "cuda:0",
    "dtype": "bfloat16",
    "vram_used_gb": 8.5,
    "vram_total_gb": 24.0,
    "optimization": {
      "enable_model_cpu_offload": true,
      "enable_attention_slicing": true,
      "enable_vae_slicing": true,
      "enable_vae_tiling": false,
      "enable_xformers": false
    }
  }
}
```

### ë°©ë²• 2: Python ì§ì ‘ ë¡œë“œ

```python
import torch
from diffusers import QwenImageEditPlusPipeline

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê¸°ë³¸ ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VRAM ì„¤ì • (íƒ 1)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ì˜µì…˜ A: ì „ì²´ GPU ë¡œë“œ (24GB+ VRAM)
# pipeline.to("cuda")

# ì˜µì…˜ B: CPU ì˜¤í”„ë¡œë”© (16GB+ VRAM, ê¶Œì¥)
pipeline.enable_model_cpu_offload()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì¶”ê°€ ìµœì í™” (ì„ íƒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
pipeline.enable_attention_slicing("auto")
pipeline.enable_vae_slicing()

# í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì„¤ì •
pipeline.set_progress_bar_config(disable=None)

print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
```

### ë¡œë“œ ìƒíƒœ í™•ì¸

```bash
curl "http://localhost:8000/api/model/status" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

### ìë™ ë¡œë“œ ê¸°ëŠ¥

ì´ í”„ë¡œì íŠ¸ëŠ” **ìë™ ë¡œë“œ** ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ì´ë¯¸ì§€ í¸ì§‘ ìš”ì²­ì´ ì˜¤ë©´ ìë™ìœ¼ë¡œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.

```bash
# ìë™ ë¡œë“œ ì„¤ì • í™•ì¸
curl "http://localhost:8000/api/settings/auto-load" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

```bash
# ìë™ ë¡œë“œ í™œì„±í™”
curl -X PUT "http://localhost:8000/api/settings/auto-load" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -H "Content-Type: application/json" \
  -d '{"enabled": true}'
```

---

## ëª¨ë¸ ì–¸ë¡œë“œ

### ë°©ë²• 1: APIë¥¼ í†µí•œ ì–¸ë¡œë“œ

```bash
curl -X POST "http://localhost:8000/api/model/unload" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

#### ì‘ë‹µ ì˜ˆì‹œ

```json
{
  "success": true,
  "message": "Model unloaded successfully",
  "vram_freed_gb": 8.5
}
```

### ë°©ë²• 2: Python ì§ì ‘ ì–¸ë¡œë“œ

```python
import gc
import torch

# íŒŒì´í”„ë¼ì¸ ì°¸ì¡° ì œê±°
del pipeline

# Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
gc.collect()

# CUDA ìºì‹œ ì •ë¦¬
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()

print("âœ… ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ!")
```

### ìë™ ì–¸ë¡œë“œ ê¸°ëŠ¥

ì´ í”„ë¡œì íŠ¸ëŠ” **ìë™ ì–¸ë¡œë“œ** ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤. ì¼ì • ì‹œê°„ ë™ì•ˆ ëª¨ë¸ì´ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ì–¸ë¡œë“œí•˜ì—¬ VRAMì„ í•´ì œí•©ë‹ˆë‹¤.

```bash
# ìë™ ì–¸ë¡œë“œ ì„¤ì • í™•ì¸
curl "http://localhost:8000/api/settings/auto-unload" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

```bash
# ìë™ ì–¸ë¡œë“œ ì„¤ì • ë³€ê²½ (30ë¶„ â†’ 60ë¶„)
curl -X PUT "http://localhost:8000/api/settings/auto-unload" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -H "Content-Type: application/json" \
  -d '{
    "enabled": true,
    "timeout_minutes": 60
  }'
```

---

## ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: APIë¥¼ í†µí•œ ì´ë¯¸ì§€ í¸ì§‘ (ê¶Œì¥)

#### íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹

```bash
curl -X POST "http://localhost:8000/api/edit/upload/single" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -F "image=@photo.jpg" \
  -F "prompt=Change the background to a sunset sky" \
  -F "num_inference_steps=20" \
  -F "true_cfg_scale=4.0"
```

#### JSON ë°©ì‹ (Base64)

```bash
curl -X POST "http://localhost:8000/api/edit/single" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -H "Content-Type: application/json" \
  -d '{
    "image": "data:image/png;base64,iVBORw0KGgoAAAANS...",
    "params": {
      "prompt": "Make the sky purple and add stars",
      "negative_prompt": " ",
      "num_inference_steps": 20,
      "true_cfg_scale": 4.0,
      "guidance_scale": 1.0,
      "seed": -1,
      "num_images_per_prompt": 1
    },
    "response_format": "url",
    "save_to_gallery": true
  }'
```

#### Python í´ë¼ì´ì–¸íŠ¸ ì™„ì „ ì˜ˆì‹œ

```python
import requests
import time
import base64
from pathlib import Path

API_URL = "http://localhost:8000"
API_KEY = "qwen-image-edit-default-key"
headers = {"X-API-Key": API_KEY}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ëª¨ë¸ ìƒíƒœ í™•ì¸ ë° ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
response = requests.get(f"{API_URL}/api/model/status", headers=headers)
status = response.json()["data"]

if not status["is_loaded"]:
    print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
    response = requests.post(f"{API_URL}/api/model/load", headers=headers)
    print(f"âœ… {response.json()['message']}")
else:
    print(f"âœ… ëª¨ë¸ ì´ë¯¸ ë¡œë“œë¨: {status['model_name']}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ì´ë¯¸ì§€ í¸ì§‘ ìš”ì²­
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with open("input_photo.jpg", "rb") as f:
    files = {"image": ("photo.jpg", f, "image/jpeg")}
    data = {
        "prompt": "Transform this photo into Studio Ghibli animation style",
        "num_inference_steps": 20,
        "true_cfg_scale": 4.0,
    }
    response = requests.post(
        f"{API_URL}/api/edit/upload/single",
        headers=headers,
        files=files,
        data=data
    )

result = response.json()
job_id = result["job_id"]
print(f"ğŸ“¤ ì‘ì—… ì œì¶œë¨: {job_id}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
while True:
    response = requests.get(f"{API_URL}/api/edit/job/{job_id}", headers=headers)
    job_status = response.json()
    
    print(f"â³ ì§„í–‰ë¥ : {job_status['progress']}%")
    
    if job_status["status"] == "completed":
        result = job_status["result"]
        image_url = f"{API_URL}{result['image']}"
        print(f"âœ… ì™„ë£Œ! ì´ë¯¸ì§€: {image_url}")
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        img_response = requests.get(image_url)
        with open("output.png", "wb") as f:
            f.write(img_response.content)
        print("ğŸ’¾ output.png ì €ì¥ ì™„ë£Œ!")
        break
        
    elif job_status["status"] == "failed":
        print(f"âŒ ì‹¤íŒ¨: {job_status['error']}")
        break
    
    time.sleep(1)
```

#### WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì§„í–‰ë¥ 

```javascript
// JavaScript ì˜ˆì‹œ
const ws = new WebSocket(`ws://localhost:8000/ws/progress/${jobId}`);

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(`ì§„í–‰ë¥ : ${data.progress}%`);
  
  if (data.status === 'completed') {
    console.log('ì™„ë£Œ!', data.result);
    ws.close();
  }
};

// Keep-alive
setInterval(() => {
  if (ws.readyState === WebSocket.OPEN) {
    ws.send('ping');
  }
}, 25000);
```

### ë°©ë²• 2: Python ì§ì ‘ ì‚¬ìš©

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
import os
import torch
from PIL import Image
from diffusers import QwenImageEditPlusPipeline

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. íŒŒì´í”„ë¼ì¸ ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)
pipeline.enable_model_cpu_offload()  # 16GB VRAM
pipeline.set_progress_bar_config(disable=None)
print("âœ… íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ì´ë¯¸ì§€ ë¡œë“œ ë° í¸ì§‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
image = Image.open("input.png").convert("RGB")

inputs = {
    "image": [image],
    "prompt": "Change the background to a sunset sky",
    "generator": torch.manual_seed(42),
    "true_cfg_scale": 4.0,
    "negative_prompt": " ",
    "num_inference_steps": 20,
    "guidance_scale": 1.0,
    "num_images_per_prompt": 1,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ì¶”ë¡  ë° ì €ì¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with torch.inference_mode():
    output = pipeline(**inputs)

output_image = output.images[0]
output_image.save("output.png")
print(f"âœ… ì €ì¥ ì™„ë£Œ: {os.path.abspath('output.png')}")
```

#### ë‹¤ì¤‘ ì´ë¯¸ì§€ í•©ì„± ì˜ˆì‹œ

```python
import torch
from PIL import Image
from diffusers import QwenImageEditPlusPipeline

pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)
pipeline.enable_model_cpu_offload()

# ë‘ ê°œì˜ ì¸ë¬¼ ì´ë¯¸ì§€
person1 = Image.open("person1.png").convert("RGB")
person2 = Image.open("person2.png").convert("RGB")

inputs = {
    "image": [person1, person2],  # ìµœëŒ€ 3ê°œê¹Œì§€ ê°€ëŠ¥
    "prompt": "The two people are sitting together at a coffee shop table, having a friendly conversation",
    "generator": torch.manual_seed(123),
    "true_cfg_scale": 4.0,
    "negative_prompt": " ",
    "num_inference_steps": 20,
    "guidance_scale": 1.0,
}

with torch.inference_mode():
    output = pipeline(**inputs)

output.images[0].save("combined_scene.png")
print("âœ… í•©ì„± ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!")
```

#### ìŠ¤íƒ€ì¼ ë³€í™˜ ì˜ˆì‹œ

```python
import torch
from PIL import Image
from diffusers import QwenImageEditPlusPipeline

pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)
pipeline.enable_model_cpu_offload()

image = Image.open("landscape.png").convert("RGB")

# ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ë³€í™˜ í”„ë¡¬í”„íŠ¸
styles = [
    ("ghibli", "Transform this into Studio Ghibli animation style"),
    ("oil_painting", "Convert this photo to an oil painting style"),
    ("cyberpunk", "Transform this into a cyberpunk neon city style"),
    ("watercolor", "Convert this to a watercolor painting"),
]

for style_name, prompt in styles:
    inputs = {
        "image": [image],
        "prompt": prompt,
        "generator": torch.manual_seed(42),
        "true_cfg_scale": 5.0,
        "negative_prompt": "blurry, distorted, low quality",
        "num_inference_steps": 25,
        "guidance_scale": 1.0,
    }
    
    with torch.inference_mode():
        output = pipeline(**inputs)
    
    output.images[0].save(f"output_{style_name}.png")
    print(f"âœ… {style_name} ìŠ¤íƒ€ì¼ ì €ì¥ ì™„ë£Œ")
```

### íŒŒë¼ë¯¸í„° ê°€ì´ë“œ

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ê¸°ë³¸ê°’ | ë²”ìœ„ | ì„¤ëª… |
|----------|------|--------|------|------|
| `image` | List[PIL.Image] | í•„ìˆ˜ | 1-3ê°œ | ì…ë ¥ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ |
| `prompt` | str | í•„ìˆ˜ | - | í¸ì§‘ ì§€ì‹œ í”„ë¡¬í”„íŠ¸ |
| `negative_prompt` | str | `" "` | - | ì œì™¸í•  ìš”ì†Œ |
| `num_inference_steps` | int | `20` | 1-100 | ì¶”ë¡  ìŠ¤í… ìˆ˜ |
| `true_cfg_scale` | float | `4.0` | 1.0-20.0 | í”„ë¡¬í”„íŠ¸ ì¶©ì‹¤ë„ |
| `guidance_scale` | float | `1.0` | 0.0-20.0 | ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ |
| `seed` / `generator` | int / Generator | -1 (ëœë¤) | - | ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ |
| `num_images_per_prompt` | int | `1` | 1-4 | ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜ |

### ìŠ¤í… ìˆ˜ ê°€ì´ë“œ

| ìŠ¤í… ìˆ˜ | í’ˆì§ˆ | ì†ë„ | ìš©ë„ |
|---------|------|------|------|
| 10-15 | ê¸°ë³¸ | ë§¤ìš° ë¹ ë¦„ | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸/ë¯¸ë¦¬ë³´ê¸° |
| 20 | ì¢‹ìŒ | ë¹ ë¦„ | ì¼ë°˜ ì‚¬ìš© (ê¶Œì¥) |
| 25-30 | ë†’ìŒ | ë³´í†µ | ê³ í’ˆì§ˆ ê²°ê³¼ë¬¼ |
| 40-50 | ë§¤ìš° ë†’ìŒ | ëŠë¦¼ | ìµœì¢… ê²°ê³¼ë¬¼ |

---

## ìµœì í™” ë°©ë²•

### ìµœì í™” ì˜µì…˜ ê°œìš”

| ì˜µì…˜ | VRAM ì ˆê° | ì†ë„ ì˜í–¥ | Windows ì§€ì› | ì„¤ëª… |
|------|-----------|-----------|--------------|------|
| `enable_model_cpu_offload` | ë†’ìŒ (-8GB) | -30% | âœ… | ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë ˆì´ì–´ë¥¼ CPUë¡œ ì´ë™ |
| `enable_attention_slicing` | ì¤‘ê°„ (-4GB) | -10% | âœ… | Attention ì—°ì‚° ë¶„í•  |
| `enable_vae_slicing` | ë‚®ìŒ (-2GB) | -5% | âœ… | VAE ì—°ì‚° ë¶„í•  |
| `enable_vae_tiling` | ì¤‘ê°„ (-3GB) | -15% | âœ… | ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ìš© íƒ€ì¼ë§ |
| `enable_xformers` | ì¤‘ê°„ (-2GB) | +20% | âš ï¸ ì„¤ì¹˜ ì£¼ì˜ | ë©”ëª¨ë¦¬ íš¨ìœ¨ì  Attention |

### APIë¥¼ í†µí•œ ìµœì í™” ì„¤ì •

#### í˜„ì¬ ìµœì í™” ì„¤ì • ì¡°íšŒ

```bash
curl "http://localhost:8000/api/model/optimization" \
  -H "X-API-Key: qwen-image-edit-default-key"
```

#### ìµœì í™” ì„¤ì • ë³€ê²½

```bash
curl -X PUT "http://localhost:8000/api/model/optimization" \
  -H "X-API-Key: qwen-image-edit-default-key" \
  -H "Content-Type: application/json" \
  -d '{
    "optimization": {
      "enable_model_cpu_offload": true,
      "enable_attention_slicing": true,
      "enable_vae_slicing": true,
      "enable_vae_tiling": false,
      "enable_xformers": false
    },
    "apply_immediately": true
  }'
```

### VRAMë³„ ê¶Œì¥ ì„¤ì •

#### 24GB+ VRAM (RTX 4090, A100)

```python
# ì „ì²´ GPU ë¡œë“œ - ìµœê³  ì†ë„
pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)
pipeline.to("cuda")
```

```json
{
  "enable_model_cpu_offload": false,
  "enable_attention_slicing": false,
  "enable_vae_slicing": false,
  "enable_vae_tiling": false,
  "enable_xformers": false
}
```

#### 16-20GB VRAM (RTX 3090, 4070 Ti Super)

```python
# CPU ì˜¤í”„ë¡œë”© - ê· í˜• ì¡íŒ ì„¤ì •
pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)
pipeline.enable_model_cpu_offload()
pipeline.enable_attention_slicing("auto")
```

```json
{
  "enable_model_cpu_offload": true,
  "enable_attention_slicing": true,
  "enable_vae_slicing": true,
  "enable_vae_tiling": false,
  "enable_xformers": false
}
```

#### 12-16GB VRAM (RTX 3060 12GB, 4060 Ti 16GB)

```python
# ìµœëŒ€ ë©”ëª¨ë¦¬ ì ˆì•½
pipeline = QwenImageEditPlusPipeline.from_pretrained(
    "ovedrive/Qwen-Image-Edit-2511-4bit",
    torch_dtype=torch.bfloat16,
)
pipeline.enable_model_cpu_offload()
pipeline.enable_attention_slicing("max")
pipeline.enable_vae_slicing()
pipeline.enable_vae_tiling()
```

```json
{
  "enable_model_cpu_offload": true,
  "enable_attention_slicing": true,
  "enable_vae_slicing": true,
  "enable_vae_tiling": true,
  "enable_xformers": false
}
```

### Windowsì—ì„œ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ìµœì í™”

âŒ **Flash Attention 2**: Linux ì „ìš©  
âš ï¸ **torch.compile**: Windowsì—ì„œ ì œí•œì  (Triton ë¯¸ì§€ì›)  
âš ï¸ **xFormers**: ì„¤ì¹˜ ì‹œ ë²„ì „ í˜¸í™˜ì„± ì£¼ì˜

### ì¢…í•© ìµœì í™” ì˜ˆì‹œ (Windows)

```python
import torch
from diffusers import QwenImageEditPlusPipeline
from PIL import Image

def create_optimized_pipeline(vram_gb: int = 16):
    """
    VRAMì— ë”°ë¥¸ ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ ìƒì„±
    
    Args:
        vram_gb: ì‚¬ìš© ê°€ëŠ¥í•œ VRAM (GB)
    """
    pipeline = QwenImageEditPlusPipeline.from_pretrained(
        "ovedrive/Qwen-Image-Edit-2511-4bit",
        torch_dtype=torch.bfloat16,
    )
    
    if vram_gb >= 24:
        # ê³ ì„±ëŠ¥: ì „ì²´ GPU
        pipeline.to("cuda")
        print("ğŸš€ ì „ì²´ GPU ëª¨ë“œ")
    elif vram_gb >= 16:
        # ê· í˜•: CPU ì˜¤í”„ë¡œë”©
        pipeline.enable_model_cpu_offload()
        pipeline.enable_attention_slicing("auto")
        pipeline.enable_vae_slicing()
        print("âš¡ CPU ì˜¤í”„ë¡œë”© ëª¨ë“œ")
    else:
        # ì €ë©”ëª¨ë¦¬: ìµœëŒ€ ì ˆì•½
        pipeline.enable_model_cpu_offload()
        pipeline.enable_attention_slicing("max")
        pipeline.enable_vae_slicing()
        pipeline.enable_vae_tiling()
        print("ğŸ’¾ ì €ë©”ëª¨ë¦¬ ëª¨ë“œ")
    
    # xFormers ì‹œë„ (ì„¤ì¹˜ëœ ê²½ìš°)
    try:
        pipeline.enable_xformers_memory_efficient_attention()
        print("âœ… xFormers í™œì„±í™”")
    except Exception:
        print("âš ï¸ xFormers ë¯¸ì„¤ì¹˜ â†’ Attention Slicing ì‚¬ìš©")
    
    pipeline.set_progress_bar_config(disable=None)
    return pipeline

# ì‚¬ìš© ì˜ˆì‹œ
pipeline = create_optimized_pipeline(vram_gb=16)

image = Image.open("input.png").convert("RGB")
prompt = "Transform this photo into anime style"

with torch.inference_mode():
    output = pipeline(
        image=[image],
        prompt=prompt,
        generator=torch.manual_seed(42),
        true_cfg_scale=4.0,
        negative_prompt=" ",
        num_inference_steps=20,
    )

output.images[0].save("output.png")
print("âœ… ì™„ë£Œ!")
```

---

## ë¬¸ì œ í•´ê²°

### CUDA Out of Memory

```
RuntimeError: CUDA out of memory
```

**í•´ê²° ë°©ë²•:**

```python
# 1. CPU ì˜¤í”„ë¡œë”© í™œì„±í™”
pipeline.enable_model_cpu_offload()

# 2. ë©”ëª¨ë¦¬ ì •ë¦¬
import gc
import torch
gc.collect()
torch.cuda.empty_cache()

# 3. ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ
from PIL import Image
image = Image.open("large_image.png")
image = image.resize((512, 512))

# 4. ì¶”ë¡  ìŠ¤í… ê°ì†Œ
inputs["num_inference_steps"] = 15
```

### ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨

```
OSError: Can't load the model
```

**í•´ê²° ë°©ë²•:**

```powershell
# diffusers ìµœì‹  ë²„ì „ ì„¤ì¹˜
pip install --upgrade git+https://github.com/huggingface/diffusers

# ìºì‹œ ì •ë¦¬
Remove-Item -Recurse -Force "$env:USERPROFILE\.cache\huggingface\hub\models--ovedrive--Qwen-Image-Edit-2511-4bit"

# ì¬ë‹¤ìš´ë¡œë“œ
huggingface-cli download ovedrive/Qwen-Image-Edit-2511-4bit
```

### í”„ë¡¬í”„íŠ¸ê°€ ë°˜ì˜ë˜ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²•:**

```python
# true_cfg_scale ì¦ê°€
inputs["true_cfg_scale"] = 5.0  # ê¸°ë³¸ê°’ 4.0ì—ì„œ ì¦ê°€

# ë” êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
# âŒ ë‚˜ìœ ì˜ˆ: "change color"
# âœ… ì¢‹ì€ ì˜ˆ: "Change the background to a bright blue sky with white clouds"
```

### Windows ê¸´ ê²½ë¡œ ì˜¤ë¥˜

```powershell
# ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰
New-ItemProperty -Path "HKLM:\SYSTEM\CurrentControlSet\Control\FileSystem" -Name "LongPathsEnabled" -Value 1 -PropertyType DWORD -Force
```

### DLL ë¡œë“œ ì˜¤ë¥˜

```powershell
# Visual C++ Redistributable ì„¤ì¹˜
winget install Microsoft.VCRedist.2015+.x64
```

---

## ê´€ë ¨ ë§í¬

| ë¦¬ì†ŒìŠ¤ | URL |
|--------|-----|
| ğŸ¤— ëª¨ë¸ í˜ì´ì§€ | https://huggingface.co/ovedrive/Qwen-Image-Edit-2511-4bit |
| ğŸ¤— ì›ë³¸ ëª¨ë¸ | https://huggingface.co/Qwen/Qwen-Image-Edit-2511 |
| ğŸ“š Diffusers ë¬¸ì„œ | https://huggingface.co/docs/diffusers |
| ğŸ“„ ì´ í”„ë¡œì íŠ¸ API ë¬¸ì„œ | [API_DOCS.md](backend/API_DOCS.md) |
| ğŸ“„ ì›ë³¸ ëª¨ë¸ ê°€ì´ë“œ | [QWEN-IMAGE-EDIT-2511.md](QWEN-IMAGE-EDIT-2511.md) |

---

<div align="center">

**Made for Qwen-Image-Edit-WebUI Project**

</div>
